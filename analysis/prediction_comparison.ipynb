{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Icsr\n",
    "\n",
    "import datasets\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import log10\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration FAERS-PubMed--BioDEX-ICSR-40aa49fec6af4868\n",
      "Found cached dataset parquet (/Users/kldooste/.cache/huggingface/datasets/FAERS-PubMed___parquet/FAERS-PubMed--BioDEX-ICSR-40aa49fec6af4868/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243635590d1c4b94bf9b48f93734a8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load validation split\n",
    "dataset = datasets.load_dataset(\"FAERS-PubMed/BioDEX-ICSR\")\n",
    "val = dataset['validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process prediction\n",
    "def postprocess(prediction):\n",
    "    prediction = prediction.replace('\\n', ' ')\n",
    "    return prediction.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predictions\n",
    "models_and_files = [\n",
    "    (\"flan-t5-large\", \"./predictions/generated-eval-predictions-flan-t5-large-s(2048)-t(258).txt\"),\n",
    "    (\"gpt-4\", \"./predictions/generated-eval-predictions-gpt-4-0314-run01.txt\")\n",
    "]\n",
    "\n",
    "models = [mf[0] for mf in models_and_files]\n",
    "\n",
    "predictions = []\n",
    "for _, file in models_and_files:\n",
    "    with open(file, 'r') as fp:\n",
    "        raw = fp.readlines()\n",
    "    raw = [postprocess(p) for p in raw]\n",
    "    predictions.append(raw)\n",
    "\n",
    "# parse icsrs\n",
    "predictions_icsrs = []\n",
    "for output in predictions:\n",
    "    icsrs = [Icsr.from_string(p) for p in output]\n",
    "    predictions_icsrs.append(icsrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load targets and inputs\n",
    "inputs = val['fulltext_processed']\n",
    "pmids = val['pmid']\n",
    "targets = [postprocess(p) for p in val['target']]\n",
    "targets_icsr = [Icsr.from_string(p) for p in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "min_length = min([len(p) for p in predictions])\n",
    "\n",
    "data = {\n",
    "    \"input\": inputs[:min_length],\n",
    "    \"pmid\": pmids[:min_length],\n",
    "    \"target_icsr\": targets_icsr[:min_length],\n",
    "    models[0] + \"_output\": predictions[0][:min_length],\n",
    "    models[0] + \"_icsr\": predictions_icsrs[0][:min_length],\n",
    "    models[1] + \"_output\": predictions[1][:min_length],\n",
    "    models[1] + \"_icsr\": predictions_icsrs[1][:min_length]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "for model in models + ['target']:\n",
    "    df[f'{model}_serious'] = df[f'{model}_icsr'].apply(lambda x: x.serious)\n",
    "    df[f'{model}_patientsex'] = df[f'{model}_icsr'].apply(lambda x: x.patientsex)\n",
    "    df[f'{model}_drugs'] = df[f'{model}_icsr'].apply(lambda x: x.drugs)\n",
    "    df[f'{model}_reactions'] = df[f'{model}_icsr'].apply(lambda x: x.reactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/33m08yl56t1f5z8g9s2h_1j80000gq/T/ipykernel_87010/2412612110.py:29: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex = df_view.to_latex(index=False, longtable=True, escape=False)\n"
     ]
    }
   ],
   "source": [
    "col_view = ['input', \n",
    "            'pmid',\n",
    "            'target_serious',\n",
    "            'flan-t5-large_serious',\n",
    "            'gpt-4_serious',\n",
    "            \"target_patientsex\",\n",
    "            \"flan-t5-large_patientsex\",\n",
    "            \"gpt-4_patientsex\",\n",
    "            \"target_drugs\",\n",
    "            \"flan-t5-large_drugs\",\n",
    "            \"gpt-4_drugs\",\n",
    "            \"target_reactions\",\n",
    "            \"flan-t5-large_reactions\",\n",
    "            \"gpt-4_reactions\"]\n",
    "\n",
    "df_view = df.reindex(columns=col_view)\n",
    "df_view['input'] = df_view['input'].apply(lambda x: x.replace('\\n\\n', ' ').replace('\\n',' '))\n",
    "\n",
    "# handle lists\n",
    "def handle_list(element):\n",
    "    if not isinstance(element, list):\n",
    "        return element\n",
    "    return ', '.join(element)\n",
    "# df_view = df_view.applymap(lambda x: str(x).replace('[','').replace(']', ''))\n",
    "df_view = df_view.applymap(handle_list)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "latex = df_view.to_latex(index=False, longtable=True, escape=False)\n",
    "latex = latex.replace('_', '\\\\_')\n",
    "\n",
    "with open('./predictions/prediction_comparison.tex', 'w') as fp:\n",
    "    fp.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pylatex\n",
    "\n",
    "# Set the desired input cutoff and text format\n",
    "input_cutoff = 2500\n",
    "n_examples = 10\n",
    "\n",
    "subtable = '''(PMID: {pmid}) {input} \\\\\\\\ \\\\\\\\ \\\\begin{{tabular}}{{lll}} \\\n",
    "\\\\hline \\\n",
    "              & serious                                       & patientsex                                      \\\\\\\\ \\\\hline \\\n",
    "target        & {target_serious}                                             & {target_patientsex}                                                         \\\\\\\\ \\\n",
    "flan-t5-large & {flan-t5-large_serious}                                      & {flan-t5-large_patientsex}                                                  \\\\\\\\ \\\n",
    "gpt-4         & {gpt-4_serious}                                              & {gpt-4_patientsex}                                                          \\\\\\\\ \\\\hline \\\n",
    "              & \\\\multicolumn{{2}}{{l}}{{drugs}}                                                                       \\\\\\\\ \\\\hline \\\n",
    "target        & \\\\multicolumn{{2}}{{p{{13.2cm}}}}{{{target_drugs}}} \\\\\\\\ \\\n",
    "flan-t5-large & \\\\multicolumn{{2}}{{p{{13.2cm}}}}{{{flan-t5-large_drugs}}} \\\\\\\\ \\\n",
    "gpt-4         & \\\\multicolumn{{2}}{{p{{13.2cm}}}}{{{gpt-4_drugs}}} \\\\\\\\ \\\\hline \\\n",
    "              & \\\\multicolumn{{2}}{{l}}{{reactions}}                                                                   \\\\\\\\ \\\\hline \\\n",
    "target        & \\\\multicolumn{{2}}{{p{{13.2cm}}}}{{{target_reactions}}}                                                 \\\\\\\\ \\\n",
    "flan-t5-large & \\\\multicolumn{{2}}{{p{{13.2cm}}}}{{{flan-t5-large_reactions}}} \\\\\\\\ \\\n",
    "gpt-4         & \\\\multicolumn{{2}}{{p{{13.2cm}}}}{{{gpt-4_reactions}}} \\\\\\\\ \\\\hline \\\n",
    "\\\\end{{tabular}} \\\\\\\\'''\n",
    "\n",
    "# Define the function to convert a row to text\n",
    "def row_to_text(row):\n",
    "    dct = dict(row)\n",
    "    dct = {k:str(pylatex.escape_latex(v)) for k,v in dct.items()}\n",
    "    dct['input'] = dct['input'][:input_cutoff] + '... [Truncated]'\n",
    "\n",
    "    return subtable.format(**dct)\n",
    "\n",
    "# Apply the row_to_text function to the DataFrame to convert it to a single column\n",
    "df_singlecol = df_view.apply(row_to_text, axis=1).iloc[:n_examples]\n",
    "\n",
    "# Set the max_colwidth option to a large value to prevent truncation\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "\n",
    "# Convert the DataFrame to LaTeX table\n",
    "latex_string = df_singlecol.to_string(index=False)\n",
    "\n",
    "# Modify the LaTeX code to create a longtable that wraps the text\n",
    "latex = \"\\\\begin{longtable}{@{}p{1.00\\\\textwidth}@{}}\\n\"\n",
    "latex += \"\\\\toprule\\n\"\n",
    "latex += \"\\\\textbf{input} \\\\tabularnewline\\n\"\n",
    "latex += \"\\\\midrule\\n\"\n",
    "latex += \"\\\\endhead\\n\"\n",
    "latex += \"\\\\bottomrule\\n\"\n",
    "latex += \"\\\\endfoot\\n\"\n",
    "latex += \"\\\\endlastfoot\\n\"\n",
    "latex += latex_string.replace('\\n', ' \\\\\\\\\\n')\n",
    "latex += \"\\\\end{longtable}\\n\"\n",
    "\n",
    "\n",
    "# Remove HTML tags\n",
    "latex = re.sub(r'[^\\S\\n]+', ' ', latex)\n",
    "\n",
    "\n",
    "\n",
    "# Deal with whitespace\n",
    "# latex = re.sub(r'\\s+',' ', latex)\n",
    "\n",
    "# Write the LaTeX table to a file\n",
    "with open('./predictions/prediction_comparison_singlecol.tex', 'w') as fp:\n",
    "    fp.write(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biodex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
