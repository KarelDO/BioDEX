{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import Icsr\n",
    "from src.utils import get_matches\n",
    "\n",
    "import datasets\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration BioDEX--raw_dataset-e1a8735a3d189f31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/BioDEX--raw_dataset to /Users/kldooste/.cache/huggingface/datasets/BioDEX___json/BioDEX--raw_dataset-e1a8735a3d189f31/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dac011911c844238495f9969a4765f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d09fa1ea92f43df8cc343cb353389c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d5a4c23e8746bfa45852755457b8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c392d61dce2548ed952c3ef9d92b21bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/47.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb240ed1452e42819961b269e80baff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda7003c385d463194c96ac34872e5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/45.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1a2df1bc834cc4bac6bdaf4daf93ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/45.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cfb67247cb423fa1f513a5619cc03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/25.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd76c14d1a44c06aec56079c750e3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b186ce8e2e334a24a1d370143c1e7427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/kldooste/.cache/huggingface/datasets/BioDEX___json/BioDEX--raw_dataset-e1a8735a3d189f31/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dffd8a5c674d8eb1d527d6849885db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65648\n"
     ]
    }
   ],
   "source": [
    "# load matches\n",
    "dataset = datasets.load_dataset(\"BioDEX/raw_dataset\")\n",
    "matches = get_matches(dataset['train'])\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest IAA\n",
    "priviledged icsr vs random icsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every article, parse all the reports\n",
    "icsrs = []\n",
    "\n",
    "for m in matches:\n",
    "    new_icsrs = [(index, Icsr.from_report(r)) for index, r in enumerate(m.reports)]\n",
    "    new_icsrs = [t for t in new_icsrs if t[1]]\n",
    "    icsrs.append(new_icsrs)\n",
    "\n",
    "all_icsrs = [i for ls in icsrs for i in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every article, sample on priviledged report and put all the others in a list\n",
    "random.seed(42)\n",
    "\n",
    "sampled_icsrs = []\n",
    "other_icsrs = []\n",
    "\n",
    "for ls in icsrs:\n",
    "    sampled = None\n",
    "    other = []\n",
    "    if ls:\n",
    "        sampled = random.choice(ls)\n",
    "        other = deepcopy(ls)\n",
    "        other.remove(sampled)\n",
    "    sampled_icsrs.append(sampled)\n",
    "    other_icsrs.append(other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total matches: \t\t65,648\n",
      "number of articles with >=1 icsr: \t51,212\n",
      "number of articles with >1 icsr: \t27,377\n"
     ]
    }
   ],
   "source": [
    "print(f'number of total matches: \\t\\t{len(matches):,}')\n",
    "print(f'number of articles with >=1 icsr: \\t{len([i for i in sampled_icsrs if i]):,}')\n",
    "print(f'number of articles with >1 icsr: \\t{len([i for i in other_icsrs if i]):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the priviledged icsr against a random icsr with the same report\n",
    "# validate the priviledged icsr against a random icsr from a random report\n",
    "random.seed(42)\n",
    "\n",
    "similar_scores = []\n",
    "random_scores = []\n",
    "for sampled, others in zip(sampled_icsrs, other_icsrs):\n",
    "    if others:\n",
    "        other = random.choice(others)\n",
    "        \n",
    "        sampled_icsr = sampled[1]\n",
    "        other_icsr = other[1]\n",
    "\n",
    "        similar_scores.append(sampled_icsr.score(other_icsr))\n",
    "\n",
    "        random_other = random.choice(all_icsrs)[1]\n",
    "        random_scores.append(sampled_icsr.score(random_other))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2432435244969848\n",
      "0.24388269245800143\n",
      "0.2428201908688846\n",
      "\n",
      "0.728383086816412\n",
      "0.7286750223845676\n",
      "0.7204383709761228\n",
      "\n",
      "Calculated over 27,377 applicable examples.\n"
     ]
    }
   ],
   "source": [
    "# aggregate scores across precision, recall and f1\n",
    "\n",
    "def agg_scores(list, index):\n",
    "    ls = [l[index] for l in list]\n",
    "    return sum(ls) / len(ls)\n",
    "\n",
    "print(agg_scores(random_scores,0))\n",
    "print(agg_scores(random_scores,1))\n",
    "print(agg_scores(random_scores,2))\n",
    "print('')\n",
    "print(agg_scores(similar_scores,0))\n",
    "print(agg_scores(similar_scores,1))\n",
    "print(agg_scores(similar_scores,2))\n",
    "print('')\n",
    "print(f'Calculated over {len(similar_scores):,} applicable examples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the priviledged icsr against a random icsr with the same report\n",
    "# validate the priviledged icsr against a random icsr from a random report\n",
    "random.seed(42)\n",
    "\n",
    "similar_scores = []\n",
    "random_scores = []\n",
    "for sampled, others in zip(sampled_icsrs, other_icsrs):\n",
    "    if others:\n",
    "        other = random.choice(others)\n",
    "        \n",
    "        sampled_icsr = sampled[1]\n",
    "        other_icsr = other[1]\n",
    "\n",
    "        similar_scores.append(sampled_icsr.score_detangled(other_icsr))\n",
    "\n",
    "        random_other = random.choice(all_icsrs)[1]\n",
    "        random_scores.append(sampled_icsr.score_detangled(random_other))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, (1.0, 1.0), (0.6666666666666666, 1.0))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_scores[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(precision, recall):\n",
    "    if precision and recall:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    return f1\n",
    "\n",
    "def agg_metric(target,metric, scores):\n",
    "    assert target in ['drug', 'reaction', 'seriousness', 'patientsex']\n",
    "    assert metric in ['precision', 'recall', 'macro_f1', 'micro_f1']\n",
    "\n",
    "    if target in ['seriousness', 'patientsex']:\n",
    "        target_index = 0 if target == 'seriousness' else 1\n",
    "        return sum([s[target_index] for s in scores]) / len(scores)\n",
    "    else:\n",
    "        target_index = 2 if target == 'drug' else 3\n",
    "\n",
    "        if 'f1' not in metric:\n",
    "            metric_index = 0 if metric == 'precision' else 1\n",
    "            metrics = [s[target_index][metric_index] for s in scores]\n",
    "            return sum(metrics)/len(metrics)\n",
    "        elif metric == 'macro_f1':\n",
    "            precision = agg_metric(target, 'precision', scores)\n",
    "            recall = agg_metric(target, 'recall', scores)\n",
    "            return f1(precision, recall)\n",
    "        else:\n",
    "            instance_level_f1_scores = [f1(s[target_index][0], s[target_index][1]) for s in scores]\n",
    "            return sum(instance_level_f1_scores) / len(instance_level_f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_f1 = f1 of aggregated precision and recall\n",
      "micro_f1 = aggregate of f1 per datapoint\n",
      "\n",
      "Random:\n",
      "drug - precision: 0.016090494816025473\n",
      "drug - recall: 0.016627807319550682\n",
      "drug - macro_f1 : 0.016354739091805216\n",
      "drug - micro_f1 : 0.01315983369399975\n",
      "reaction - precision: 0.010403785436066432\n",
      "reaction - recall: 0.011783976815589797\n",
      "reaction - macro_f1 : 0.011050953672791058\n",
      "reaction - micro_f1 : 0.009031875990767883\n",
      "\n",
      "IAA:\n",
      "drug - precision: 0.7127620877631963\n",
      "drug - recall: 0.7114308446249148\n",
      "drug - macro_f1 : 0.7120958440142044\n",
      "drug - micro_f1 : 0.6827454806898535\n",
      "reaction - precision: 0.5612208652016648\n",
      "reaction - recall: 0.5634279150444074\n",
      "reaction - macro_f1 : 0.5623222245273879\n",
      "reaction - micro_f1 : 0.5196896810138785\n"
     ]
    }
   ],
   "source": [
    "print('macro_f1 = f1 of aggregated precision and recall')\n",
    "print('micro_f1 = aggregate of f1 per datapoint')\n",
    "print()\n",
    "print('Random:')\n",
    "print('drug - precision:', agg_metric('drug', 'precision', random_scores))\n",
    "print('drug - recall:', agg_metric('drug', 'recall', random_scores))\n",
    "print('drug - macro_f1 :', agg_metric('drug', 'macro_f1', random_scores))\n",
    "print('drug - micro_f1 :', agg_metric('drug', 'micro_f1', random_scores))\n",
    "print('reaction - precision:', agg_metric('reaction', 'precision', random_scores))\n",
    "print('reaction - recall:', agg_metric('reaction', 'recall', random_scores))\n",
    "print('reaction - macro_f1 :', agg_metric('reaction', 'macro_f1', random_scores))\n",
    "print('reaction - micro_f1 :', agg_metric('reaction', 'micro_f1', random_scores))\n",
    "\n",
    "print()\n",
    "print('IAA:')\n",
    "print('drug - precision:', agg_metric('drug', 'precision', similar_scores))\n",
    "print('drug - recall:', agg_metric('drug', 'recall', similar_scores))\n",
    "print('drug - macro_f1 :', agg_metric('drug', 'macro_f1', similar_scores))\n",
    "print('drug - micro_f1 :', agg_metric('drug', 'micro_f1', similar_scores))\n",
    "print('reaction - precision:', agg_metric('reaction', 'precision', similar_scores))\n",
    "print('reaction - recall:', agg_metric('reaction', 'recall', similar_scores))\n",
    "print('reaction - macro_f1 :', agg_metric('reaction', 'macro_f1', similar_scores))\n",
    "print('reaction - micro_f1 :', agg_metric('reaction', 'micro_f1', similar_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different IAA\n",
    "priviledged icsr vs random icsr that is not of the same company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every article, parse all the reports\n",
    "# also keep track of the company that submitted the icsr\n",
    "def get_company(report):\n",
    "    comp = None\n",
    "    if report.companynumb:\n",
    "        if '-' in report.companynumb:\n",
    "            comp = report.companynumb.split('-')[1].strip().title()\n",
    "    return comp\n",
    "\n",
    "icsrs = []\n",
    "\n",
    "for m in matches:\n",
    "    new_icsrs = [(index, get_company(r) ,Icsr.from_report(r)) for index, r in enumerate(m.reports)]\n",
    "    new_icsrs = [t for t in new_icsrs if t[1] and t[2]]\n",
    "    icsrs.append(new_icsrs)\n",
    "\n",
    "all_icsrs = [i for ls in icsrs for i in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every article, sample on priviledged report and put all the others in a list\n",
    "random.seed(42)\n",
    "\n",
    "sampled_icsrs = []\n",
    "other_icsrs = []\n",
    "\n",
    "for ls in icsrs:\n",
    "    sampled = None\n",
    "    other = []\n",
    "    if ls:\n",
    "        sampled = random.choice(ls)\n",
    "        other = deepcopy(ls)\n",
    "        other.remove(sampled)\n",
    "    sampled_icsrs.append(sampled)\n",
    "    other_icsrs.append(other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total matches: \t\t65,648\n",
      "number of articles with >=1 icsr: \t48,708\n",
      "number of articles with >1 icsr: \t25,675\n"
     ]
    }
   ],
   "source": [
    "print(f'number of total matches: \\t\\t{len(matches):,}')\n",
    "print(f'number of articles with >=1 icsr: \\t{len([i for i in sampled_icsrs if i]):,}')\n",
    "print(f'number of articles with >1 icsr: \\t{len([i for i in other_icsrs if i]):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 19254 comparison same article different company\n"
     ]
    }
   ],
   "source": [
    "# validate the priviledged icsr against a random icsr with the same report\n",
    "# validate the priviledged icsr against a random icsr from a random report\n",
    "random.seed(42)\n",
    "\n",
    "similar_scores = []\n",
    "random_scores = []\n",
    "for sampled, others in zip(sampled_icsrs, other_icsrs):\n",
    "    if others:\n",
    "        other = random.choice(others)\n",
    "        \n",
    "\n",
    "        # only compare for different companies\n",
    "        if sampled[1] != other[1]:\n",
    "            sampled_icsr = sampled[2]\n",
    "            other_icsr = other[2]\n",
    "        \n",
    "            similar_scores.append(sampled_icsr.score(other_icsr))\n",
    "\n",
    "            random_other = random.choice(all_icsrs)[2]\n",
    "            random_scores.append(sampled_icsr.score(random_other))\n",
    "\n",
    "print(f'Made {len(similar_scores)} comparison same article different company')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24530324070215034\n",
      "0.24606646000919297\n",
      "0.24492883153940762\n",
      "\n",
      "0.7316943442414694\n",
      "0.7321459690671169\n",
      "0.7233746876594158\n",
      "\n",
      "Calculated over 19,254 applicable examples.\n"
     ]
    }
   ],
   "source": [
    "print(agg_scores(random_scores,0))\n",
    "print(agg_scores(random_scores,1))\n",
    "print(agg_scores(random_scores,2))\n",
    "print('')\n",
    "print(agg_scores(similar_scores,0))\n",
    "print(agg_scores(similar_scores,1))\n",
    "print(agg_scores(similar_scores,2))\n",
    "print('')\n",
    "print(f'Calculated over {len(similar_scores):,} applicable examples.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
